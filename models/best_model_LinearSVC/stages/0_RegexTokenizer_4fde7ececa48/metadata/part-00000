{"class":"org.apache.spark.ml.feature.RegexTokenizer","timestamp":1772118996403,"sparkVersion":"3.5.1","uid":"RegexTokenizer_4fde7ececa48","paramMap":{"outputCol":"tokens","pattern":"\\W+","minTokenLength":2,"inputCol":"text"},"defaultParamMap":{"outputCol":"RegexTokenizer_4fde7ececa48__output","gaps":true,"pattern":"\\s+","minTokenLength":1,"toLowercase":true}}
